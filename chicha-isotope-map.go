package main

import (
	"archive/zip"
	"bytes"
	"embed"
	"net"
	"encoding/json"
	"flag"
	"fmt"
	"errors"
	"html/template"
	"io"
	"io/fs"
	"io/ioutil"
	"log"
	"os"
	"context"
	"crypto/tls"
	"runtime"
	"math"
	"math/rand"
	"mime/multipart"
	"net/http"
	"path/filepath"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"time"
	"golang.org/x/crypto/acme/autocert"

	"chicha-isotope-map/pkg/database"
)

//go:embed public_html/*
var content embed.FS

var doseData database.Data

var domain = flag.String("domain", "", "Use 80 and 443 ports. Automatic HTTPS cert via Let's Encrypt.")
var dbType = flag.String("db-type", "genji", "Type of the database driver: genji, sqlite, or pgx (postgresql)")
var dbPath = flag.String("db-path", "", "Path to the database file(defaults to the current folder, applicable for genji, sqlite drivers.)")
var dbHost = flag.String("db-host", "127.0.0.1", "Database host (applicable for pgx driver)")
var dbPort = flag.Int("db-port", 5432, "Database port (applicable for pgx driver)")
var dbUser = flag.String("db-user", "postgres", "Database user (applicable for pgx driver)")
var dbPass = flag.String("db-pass", "", "Database password (applicable for pgx driver)")
var dbName = flag.String("db-name", "IsotopePathways", "Database name (applicable for pgx driver)")
var pgSSLMode = flag.String("pg-ssl-mode", "prefer", "PostgreSQL SSL mode: disable, allow, prefer, require, verify-ca, or verify-full")
var port = flag.Int("port", 8765, "Port for running the server")
var version = flag.Bool("version", false, "Show the application version")
var defaultLat = flag.Float64("default-lat", 44.08832, "Default map latitude")
var defaultLon = flag.Float64("default-lon", 42.97577, "Default map longitude")
var defaultZoom = flag.Int("default-zoom", 11, "Default map zoom")
var defaultLayer = flag.String("default-layer", "OpenStreetMap", `Default base layer: "OpenStreetMap" or "Google Satellite"`)

var CompileVersion = "dev"

var db *database.Database

// ==========
// –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Å–ª–∏—è–Ω–∏—è –º–∞—Ä–∫–µ—Ä–æ–≤
// ==========
const (
	markerRadiusPx = 10.0 // —Ä–∞–¥–∏—É—Å –∫—Ä—É–∂–∫–∞ –≤ –ø–∏–∫—Å–µ–ª—è—Ö
  minValidTS     = 1262304000   // 2010-01-01 00:00:00 UTC
)

type SpeedRange struct{ Min, Max float64 }

var speedCatalog = map[string]SpeedRange{
	"ped":   {0, 7},      // < 7 –º/—Å   (~0-25 –∫–º/—á)
	"car":   {7, 70},     // 7‚Äì70 –º/—Å  (~25-250 –∫–º/—á)
	"plane": {70, 500},   // > 70 –º/—Å  (~250-1800 –∫–º/—á)
}


// withServerHeader –æ–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç –ª—é–±–æ–π http.Handler, –¥–æ–±–∞–≤–ª—è—è
// –∑–∞–≥–æ–ª–æ–≤–æ–∫ "Server: chicha-isotope-map/<CompileVersion>".
//
// –ù–∞ –∑–∞–ø—Ä–æ—Å HEAD –∫ ‚Äú/‚Äù —Å—Ä–∞–∑—É –æ—Ç–≤–µ—á–∞–µ—Ç 200 OK –±–µ–∑ —Ç–µ–ª–∞, —á—Ç–æ–±—ã
// –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ —Å–µ—Ä–≤–∏—Å –∂–∏–≤.

func withServerHeader(h http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Server", "chicha-isotope-map/"+CompileVersion)

		if r.Method == http.MethodHead && r.URL.Path == "/" {
			w.WriteHeader(http.StatusOK)
			return
		}
		h.ServeHTTP(w, r)
	})
}



// serveWithDomain –∑–∞–ø—É—Å–∫–∞–µ—Ç:
//   ‚Ä¢ :80  ‚Äî ACME HTTP-01 + 301-redirect –Ω–∞ https://<domain>/‚Ä¶
//   ‚Ä¢ :443 ‚Äî HTTPS —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞–º–∏ Let‚Äôs Encrypt.
//
// –ù–æ–≤–æ–µ: –µ—Å–ª–∏ autocert –Ω–µ –º–æ–∂–µ—Ç –≤—ã–¥–∞—Ç—å cert (–ª—é–±–æ–π host/SNI),
//        —Å–µ—Ä–≤–µ—Ä –≤—Å—ë-—Ç–∞–∫–∏ –æ—Ç–¥–∞—ë—Ç —Ä–∞–Ω–µ–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–π fallback-cert,
//        —Ç–µ–º —Å–∞–º—ã–º —É—Å—Ç—Ä–∞–Ω—è—è ¬´host not configured¬ª –≤ –ª–æ–≥–∞—Ö.
//
// –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: TLS ‚â• 1.0, ALPN h2/http1.1/http1.0.
// –í—Å–µ –æ—à–∏–±–∫–∏ —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è.

func serveWithDomain(domain string, handler http.Handler) {
	// ----------- ACME manager -----------
	certMgr := &autocert.Manager{
		Prompt: autocert.AcceptTOS,
		Cache:  autocert.DirCache("certs"),
		HostPolicy: func(ctx context.Context, host string) error {
			// –†–∞–∑—Ä–µ—à–∞–µ–º –≥–æ–ª—ã–π –∏ www.<domain>
			if host == domain || host == "www."+domain {
				return nil
			}
			// IP-–∞–¥—Ä–µ—Å? ‚Äî –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º, –ø—Ä–æ—Å—Ç–æ –Ω–µ –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å cert.
			if net.ParseIP(host) != nil {
				return nil
			}
			return errors.New("acme/autocert: host not configured")
		},
	}

	// ----------- :80 (challenge + redirect) -----------
	go func() {
		mux80 := http.NewServeMux()
		mux80.Handle("/.well-known/acme-challenge/", certMgr.HTTPHandler(nil))
		mux80.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
			target := "https://" + domain + r.URL.RequestURI()
			http.Redirect(w, r, target, http.StatusMovedPermanently)
		})

		log.Printf("HTTP  server (ACME+redirect) ‚ûú :80")
		if err := (&http.Server{
			Addr:              ":80",
			Handler:           mux80,
			ReadHeaderTimeout: 10 * time.Second,
		}).ListenAndServe(); err != nil {
			log.Printf("HTTP  server error: %v", err)
		}
	}()

	// ----------- –µ–∂–µ–¥–Ω–µ–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞ -----------
	go func() {
		t := time.NewTicker(24 * time.Hour)
		defer t.Stop()
		for range t.C {
			if _, err := certMgr.GetCertificate(&tls.ClientHelloInfo{ServerName: domain}); err != nil {
				log.Printf("autocert renewal check: %v", err)
			}
		}
	}()

	// ----------- :443 (HTTPS) -----------
	tlsCfg := certMgr.TLSConfig()
	tlsCfg.MinVersion = tls.VersionTLS10
	tlsCfg.NextProtos = append([]string{"http/1.0"}, tlsCfg.NextProtos...)

	// fallback-—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç –¥–ª—è IP / —Å—Ç—Ä–∞–Ω–Ω—ã—Ö SNI
	var defaultCert *tls.Certificate
	go func() {
		for defaultCert == nil {
			if c, err := certMgr.GetCertificate(&tls.ClientHelloInfo{ServerName: domain}); err == nil {
				defaultCert = c
			}
			time.Sleep(time.Minute)
		}
	}()
	tlsCfg.GetCertificate = func(chi *tls.ClientHelloInfo) (*tls.Certificate, error) {
		c, err := certMgr.GetCertificate(chi)
		if err == nil {
			return c, nil
		}
		// –õ—é–±–æ–π —Å–±–æ–π ‚Äî –ø—ã—Ç–∞–µ–º—Å—è –æ—Ç–¥–∞—Ç—å fallback-cert (–µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å)
		if defaultCert != nil {
			return defaultCert, nil
		}
		// –ü–æ–∫–∞ fallback –Ω–µ—Ç ‚Äî –ø–æ–≤—Ç–æ—Ä—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –æ—à–∏–±–∫—É
		return nil, err
	}

	log.Printf("HTTPS server for %s ‚ûú :443 (TLS ‚â•1.0, ALPN h2/http1.1/1.0)", domain)
	if err := (&http.Server{
		Addr:              ":443",
		Handler:           handler,
		TLSConfig:         tlsCfg,
		ReadHeaderTimeout: 10 * time.Second,
	}).ListenAndServeTLS("", ""); err != nil {
		log.Printf("HTTPS server error: %v", err)
	}
}


// GenerateSerialNumber –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç TrackID
func GenerateSerialNumber() string {
	const base62Chars = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
	const maxLength = 6

	timestamp := uint64(time.Now().UnixNano() / 1e6) // –≤—Ä–µ–º—è –≤ –º—Å
	encoded := ""
	base := uint64(len(base62Chars))

	for timestamp > 0 && len(encoded) < maxLength {
		remainder := timestamp % base
		encoded = string(base62Chars[remainder]) + encoded
		timestamp = timestamp / base
	}

	rand.Seed(time.Now().UnixNano())
	for len(encoded) < maxLength {
		encoded += string(base62Chars[rand.Intn(len(base62Chars))])
	}

	return encoded
}

// convertRhToSv –∏ convertSvToRh - –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–µ—Ä–µ–≤–æ–¥–∞
func convertRhToSv(markers []database.Marker) []database.Marker {
	filteredMarkers := []database.Marker{}
	const conversionFactor = 0.01 // 1 Rh = 0.01 Sv

	for _, newMarker := range markers {
		newMarker.DoseRate = newMarker.DoseRate * conversionFactor
		filteredMarkers = append(filteredMarkers, newMarker)
	}
	return filteredMarkers
}

// filterZeroMarkers —É–±–∏—Ä–∞–µ—Ç –º–∞—Ä–∫–µ—Ä—ã —Å –Ω—É–ª–µ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –¥–æ–∑—ã
func filterZeroMarkers(markers []database.Marker) []database.Marker {
	filteredMarkers := []database.Marker{}
	for _, m := range markers {
		if m.DoseRate == 0 {
			continue
		}
		filteredMarkers = append(filteredMarkers, m)
	}
	return filteredMarkers
}


// NEW ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
func isValidDate(ts int64) bool {
    // –¥–æ–ø—É—Å—Ç–∏–º–æ ¬´—Å–µ–≥–æ–¥–Ω—è –ø–ª—é—Å —Å—É—Ç–∫–∏¬ª —Å —É—á—ë—Ç–æ–º —á–∞—Å–æ–≤—ã—Ö –ø–æ—è—Å–æ–≤
    max := time.Now().Add(24 * time.Hour).Unix()
    return ts >= minValidTS && ts <= max
}

func filterInvalidDateMarkers(markers []database.Marker) []database.Marker {
    out := markers[:0]
    for _, m := range markers {
        if isValidDate(m.Date) {
            out = append(out, m)
        }
    }
    return out
}


// –ü—Ä–æ–µ–∫—Ü–∏—è Web Mercator –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç —à–∏—Ä–æ—Ç—É/–¥–æ–ª–≥–æ—Ç—É –≤ "–º–µ—Ç—Ä—ã".
// –§–æ—Ä–º—É–ª—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ, –∑–¥–µ—Å—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ –ø–∏–∫—Å–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã.
func latLonToWebMercator(lat, lon float64) (x, y float64) {
	// const —Ä–∞–¥–∏—É—Å –ó–µ–º–ª–∏ –¥–ª—è WebMercator
	const originShift = 2.0 * math.Pi * 6378137.0 / 2.0

	x = lon * originShift / 180.0
	y = math.Log(math.Tan((90.0+lat)*math.Pi/360.0)) / (math.Pi / 180.0)
	y = y * originShift / 180.0
	return x, y
}

// webMercatorToPixel –ø–µ—Ä–µ–≤–æ–¥–∏—Ç Web Mercator –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (x,y) –≤ –ø–∏–∫—Å–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω–æ–º –∑—É–º–µ.
func webMercatorToPixel(x, y float64, zoom int) (px, py float64) {
	// —Ç–∞–π–ª 256x256, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤ 2^zoom
	scale := math.Exp2(float64(zoom))
	px = (x + 2.0*math.Pi*6378137.0/2.0) / (2.0 * math.Pi * 6378137.0) * 256.0 * scale
	py = (2.0*math.Pi*6378137.0/2.0 - y) / (2.0 * math.Pi * 6378137.0) * 256.0 * scale
	return
}

// latLonToPixel - —É–¥–æ–±–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞
func latLonToPixel(lat, lon float64, zoom int) (px, py float64) {
	x, y := latLonToWebMercator(lat, lon)
	return webMercatorToPixel(x, y, zoom)
}

// mergeMarkersByZoom ‚Äú—Å–ª–∏–≤–∞–µ—Ç‚Äù (—É—Å—Ä–µ–¥–Ω—è–µ—Ç) –º–∞—Ä–∫–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è –≤ –ø–∏–∫—Å–µ–ª—å–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö
// –Ω–∞ —Ç–µ–∫—É—â–µ–º –∑—É–º–µ. –ï—Å–ª–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–∞–º–∏ –º–µ–Ω—å—à–µ 2*markerRadiusPx (–ø–ª—é—Å 1px ‚Äú–∑–∞–ø–∞—Å‚Äù), —Ç–æ –æ–±—ä–µ–¥–∏–Ω—è–µ–º.
func mergeMarkersByZoom(markers []database.Marker, zoom int, radiusPx float64) []database.Marker {
	if len(markers) == 0 {
		return nil
	}

	// –°–Ω–∞—á–∞–ª–∞ –≥–æ—Ç–æ–≤–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –ø–∏–∫—Å–µ–ª—å–Ω—ã–º–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
	type markerPixel struct {
		Marker    database.Marker
		Px, Py    float64
		MergedIdx int // -1, –µ—Å–ª–∏ –Ω–∏ —Å –∫–µ–º –µ—â—ë –Ω–µ —Å–ª–∏–≤–∞–ª—Å—è
	}

	mPixels := make([]markerPixel, len(markers))
	for i, m := range markers {
		px, py := latLonToPixel(m.Lat, m.Lon, zoom)
		mPixels[i] = markerPixel{
			Marker:    m,
			Px:        px,
			Py:        py,
			MergedIdx: -1,
		}
	}

	var result []database.Marker

	// –ñ–∞–¥–Ω–æ –∏–¥—ë–º –ø–æ —Å–ø–∏—Å–∫—É, —Å–ª–∏–≤–∞–µ–º –±–ª–∏–∑–∫–∏–µ –¥—Ä—É–≥ –∫ –¥—Ä—É–≥—É
	for i := 0; i < len(mPixels); i++ {
		if mPixels[i].MergedIdx != -1 {
			// —É–∂–µ —Å–ª–∏—Ç —Å –∫–µ–º-—Ç–æ
			continue
		}
		// –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π –∫–ª–∞—Å—Ç–µ—Ä
		cluster := []markerPixel{mPixels[i]}
		mPixels[i].MergedIdx = i

		// –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ—Ö –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö
		for j := i + 1; j < len(mPixels); j++ {
			if mPixels[j].MergedIdx != -1 {
				continue
			}
			dist := math.Hypot(mPixels[i].Px-mPixels[j].Px, mPixels[i].Py-mPixels[j].Py)
			if dist < 2.0*radiusPx {
				// –°–ª–∏–≤–∞–µ–º
				cluster = append(cluster, mPixels[j])
				mPixels[j].MergedIdx = i // –∑–Ω–∞—á–∏—Ç, —Å–ª–∏—Ç –∫ –∫–ª–∞—Å—Ç–µ—Ä—É i
			}
		}

		// –£—Å—Ä–µ–¥–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä–∞
		var sumLat, sumLon, sumDose, sumCount float64
		var latestDate int64
		for _, c := range cluster {
			sumLat += c.Marker.Lat
			sumLon += c.Marker.Lon
			sumDose += c.Marker.DoseRate
			sumCount += c.Marker.CountRate
			// –≤–æ–∑—å–º—ë–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
			if c.Marker.Date > latestDate {
				latestDate = c.Marker.Date
			}
		}
		n := float64(len(cluster))
		avgLat := sumLat / n
		avgLon := sumLon / n
		avgDose := sumDose / n
		avgCount := sumCount / n

		var sumSpeed float64
		for _, c := range cluster {
			sumSpeed += c.Marker.Speed
		}
		avgSpeed := sumSpeed / n

		// –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π —Å–ª–∏—Ç—ã–π –º–∞—Ä–∫–µ—Ä
		newMarker := database.Marker{
			Lat:       avgLat,
			Lon:       avgLon,
			DoseRate:  avgDose,
			CountRate: avgCount,
			Date:      latestDate,
			Speed:     avgSpeed,
			Zoom:      zoom,
			TrackID:   cluster[0].Marker.TrackID, // –±–µ—Ä–µ–º —Ö–æ—Ç—è –±—ã —É –ø–µ—Ä–≤–æ–≥–æ
		}
		result = append(result, newMarker)
	}

	return result
}

func calculateSpeedForMarkers(markers []database.Marker) []database.Marker {
	if len(markers) == 0 { // <-- –¥–æ–±–∞–≤–ª–µ–Ω–æ
		return markers
	}

	sort.Slice(markers, func(i, j int) bool { return markers[i].Date < markers[j].Date })

	for i := 1; i < len(markers); i++ {
		prev, curr := markers[i-1], markers[i]
		dist := haversineDistance(prev.Lat, prev.Lon, curr.Lat, curr.Lon)
		timeDiff := curr.Date - prev.Date
		if timeDiff > 0 {
			speed := dist / float64(timeDiff)
			if speed >= 0 && speed <= 300 {
				markers[i].Speed = speed
			} else {
				markers[i].Speed = markers[i-1].Speed
			}
		}
	}

	// –û–±–Ω–æ–≤–ª—ë–Ω–Ω–∞—è –∑–∞—â–∏—Ç–∞
	if len(markers) > 1 {
		markers[0].Speed = markers[1].Speed
	} else {
		markers[0].Speed = 0
	}
	return markers
}

func haversineDistance(lat1, lon1, lat2, lon2 float64) float64 {
	const R = 6371000
	phi1, phi2 := lat1*math.Pi/180, lat2*math.Pi/180
	dPhi, dLambda := (lat2-lat1)*math.Pi/180, (lon2-lon1)*math.Pi/180
	a := math.Sin(dPhi/2)*math.Sin(dPhi/2) + math.Cos(phi1)*math.Cos(phi2)*math.Sin(dLambda/2)*math.Sin(dLambda/2)
	return 2 * R * math.Atan2(math.Sqrt(a), math.Sqrt(1-a))
}

// precomputeMarkersForAllZoomLevels –≤—ã—á–∏—Å–ª—è–µ—Ç –∑–∞—Ä–∞–Ω–µ–µ –º–∞—Ä–∫–µ—Ä—ã –¥–ª—è –≤—Å–µ—Ö (1..20) —É—Ä–æ–≤–Ω–µ–π –∑—É–º–∞
// –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –º–∞—Å—Å–∏–≤
// –ë–∞–∑–æ–≤—ã–π —Ä–∞–¥–∏—É—Å, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º –Ω–∞ 20-–º –∑—É–º–µ –º–∞—Ä–∫–µ—Ä—ã —Å–æ–≤—Å–µ–º –Ω–µ —Å–ª–∏–≤–∞—é—Ç—Å—è

func radiusForZoom(zoom int) float64 {
	// –ª–∏–Ω–µ–π–Ω–∞—è —à–∫–∞–ª–∞: z=20 ‚Üí 10 px, z=10 ‚Üí 5 px, z=5 ‚Üí 2.5 px ‚Ä¶
	return markerRadiusPx * float64(zoom) / 20.0
}

func precomputeMarkersForAllZoomLevels(src []database.Marker) []database.Marker {
	var out []database.Marker
	for z := 1; z <= 20; z++ {
		merged := mergeMarkersByZoom(src, z, radiusForZoom(z))
		out = append(out, merged...)
	}
	return out
}

// =====================
// –¢—Ä–∞–Ω—Å–ª–µ–π—Ç
// =====================
var translations map[string]map[string]string

func loadTranslations(fs embed.FS, filename string) {
	file, err := fs.Open(filename)
	if err != nil {
		log.Fatalf("Error opening translation file: %v", err)
	}
	defer file.Close()

	data, err := ioutil.ReadAll(file)
	if err != nil {
		log.Fatalf("Error reading translation file: %v", err)
	}

	err = json.Unmarshal(data, &translations)
	if err != nil {
		log.Fatalf("Error parsing translations: %v", err)
	}
}

func getPreferredLanguage(r *http.Request) string {
	langHeader := r.Header.Get("Accept-Language")
	supportedLanguages := []string{
		"en", "zh", "es", "hi", "ar", "fr", "ru", "pt", "de", "ja", "tr", "it",
		"ko", "pl", "uk", "mn", "no", "fi", "ka", "sv", "he", "nl", "el", "hu",
		"cs", "ro", "th", "vi", "id", "ms", "bg", "lt", "et", "lv", "sl",
	}
	langs := strings.Split(langHeader, ",")
	for _, lang := range langs {
		lang = strings.TrimSpace(strings.SplitN(lang, ";", 2)[0])
		for _, supported := range supportedLanguages {
			if strings.HasPrefix(lang, supported) {
				return supported
			}
		}
	}
	return "en"
}

// =====================
// –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤
// =====================
func parseFloat(value string) float64 {
	parsedValue, _ := strconv.ParseFloat(value, 64)
	return parsedValue
}


func getTimeZoneByLongitude(lon float64) *time.Location {
	switch {
	case lon >= -10 && lon <= 0:
		loc, _ := time.LoadLocation("Europe/London")
		return loc
	case lon > 0 && lon <= 15:
		loc, _ := time.LoadLocation("Europe/Berlin")
		return loc
	case lon > 15 && lon <= 30:
		loc, _ := time.LoadLocation("Europe/Kiev")
		return loc
	case lon > 30 && lon <= 45:
		loc, _ := time.LoadLocation("Europe/Moscow")
		return loc
	case lon > 45 && lon <= 60:
		loc, _ := time.LoadLocation("Asia/Yekaterinburg")
		return loc
	case lon > 60 && lon <= 90:
		loc, _ := time.LoadLocation("Asia/Novosibirsk")
		return loc
	case lon > 90 && lon <= 120:
		loc, _ := time.LoadLocation("Asia/Irkutsk")
		return loc
	case lon > 120 && lon <= 135:
		loc, _ := time.LoadLocation("Asia/Yakutsk")
		return loc
	case lon > 135 && lon <= 180:
		loc, _ := time.LoadLocation("Asia/Vladivostok")
		return loc

	case lon >= -180 && lon < -150:
		loc, _ := time.LoadLocation("America/Anchorage")
		return loc
	case lon >= -150 && lon < -120:
		loc, _ := time.LoadLocation("America/Los_Angeles")
		return loc
	case lon >= -120 && lon < -90:
		loc, _ := time.LoadLocation("America/Denver")
		return loc
	case lon >= -90 && lon < -60:
		loc, _ := time.LoadLocation("America/Chicago")
		return loc
	case lon >= -60 && lon < -30:
		loc, _ := time.LoadLocation("America/New_York")
		return loc
	case lon >= -30 && lon < 0:
		loc, _ := time.LoadLocation("America/Halifax")
		return loc

	case lon >= 60 && lon < 75:
		loc, _ := time.LoadLocation("Asia/Karachi")
		return loc
	case lon >= 75 && lon < 90:
		loc, _ := time.LoadLocation("Asia/Kolkata")
		return loc
	case lon >= 90 && lon < 105:
		loc, _ := time.LoadLocation("Asia/Dhaka")
		return loc
	case lon >= 105 && lon < 120:
		loc, _ := time.LoadLocation("Asia/Bangkok")
		return loc
	case lon >= 120 && lon < 135:
		loc, _ := time.LoadLocation("Asia/Shanghai")
		return loc
	case lon >= 135 && lon < 150:
		loc, _ := time.LoadLocation("Asia/Tokyo")
		return loc
	case lon >= 150 && lon <= 180:
		loc, _ := time.LoadLocation("Australia/Sydney")
		return loc

	default:
		loc, _ := time.LoadLocation("UTC")
		return loc
	}
}


// -----------------------------------------------------------------------------
// extractDoseRate ‚Äî –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–∑—É –∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Ç–µ–∫—Å—Ç–∞.
//  ‚Ä¢ ¬´12.3 ¬µR/h¬ª  ‚Üí 0.123 ¬µSv/h   (1 ¬µR/h ‚âà 0.01 ¬µSv/h)
//  ‚Ä¢ ¬´0.136 uSv/h¬ª ‚Üí 0.136 ¬µSv/h  (Safecast)
// -----------------------------------------------------------------------------
func extractDoseRate(s string) float64 {
	¬µr := regexp.MustCompile(`(?i)(\d+(?:\.\d+)?)\s*¬µ?R/h`)
	if m := ¬µr.FindStringSubmatch(s); len(m) > 0 {
		return parseFloat(m[1]) / 100.0 // ¬µR/h ‚Üí ¬µSv/h
	}

	usv := regexp.MustCompile(`(?i)(\d+(?:\.\d+)?)\s*uSv/h`)
	if m := usv.FindStringSubmatch(s); len(m) > 0 {
		return parseFloat(m[1])          // —É–∂–µ –≤ ¬µSv/h
	}
	return 0
}

// -----------------------------------------------------------------------------
// extractCountRate ‚Äî –∏—â–µ—Ç —Å—á—ë—Ç ‚Ä¢ cps ‚Ä¢ CPM –∏ –Ω–æ—Ä–º–∏—Ä—É–µ—Ç –∫ cps.
// -----------------------------------------------------------------------------
func extractCountRate(s string) float64 {
	cps := regexp.MustCompile(`(?i)(\d+(?:\.\d+)?)\s*cps`)
	if m := cps.FindStringSubmatch(s); len(m) > 0 {
		return parseFloat(m[1])
	}

	cpm := regexp.MustCompile(`(?i)CPM\s*Value\s*=\s*(\d+(?:\.\d+)?)`)
	if m := cpm.FindStringSubmatch(s); len(m) > 0 {
		return parseFloat(m[1]) / 60.0 // 1 –º–∏–Ω ‚Üí —Å–µ–∫—É–Ω–¥—ã
	}
	return 0
}

// -----------------------------------------------------------------------------
// parseDate ‚Äî –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–±–∞ —Ñ–æ—Ä–º–∞—Ç–∞:
//  ‚Ä¢ ¬´May 23, 2012 04:10:08¬ª   (—Å—Ç–∞—Ä—ã–π .rctrk / AtomFast KML)
//  ‚Ä¢ ¬´2012/05/23 04:10:08¬ª     (Safecast)
// loc ‚Äî —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å, —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–π –ø–æ –¥–æ–ª–≥–æ—Ç–µ (–º–æ–∂–Ω–æ nil ‚Üí UTC).
// -----------------------------------------------------------------------------
func parseDate(s string, loc *time.Location) int64 {
	if loc == nil {
		loc = time.UTC
	}

	if m := regexp.MustCompile(`([A-Za-z]{3} \d{1,2}, \d{4} \d{2}:\d{2}:\d{2})`).FindStringSubmatch(s); len(m) > 0 {
		const layout = "Jan 2, 2006 15:04:05"
		if t, err := time.ParseInLocation(layout, m[1], loc); err == nil {
			return t.Unix()
		}
	}
	if m := regexp.MustCompile(`(\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2})`).FindStringSubmatch(s); len(m) > 0 {
		const layout = "2006/01/02 15:04:05"
		if t, err := time.ParseInLocation(layout, m[1], loc); err == nil {
			return t.Unix()
		}
	}
	return 0
}

// -----------------------------------------------------------------------------
// parseKML ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä KML (–æ–±—ã—á–Ω—ã–π + Safecast).
// –î–ª—è –∫–∞–∂–¥–æ–π <Placemark> –∏—â–µ—Ç:
//  ‚Ä¢ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É  (–ø–µ—Ä–≤—ã–µ lon,lat)
//  ‚Ä¢ –¥–æ–∑—É        ‚Äî <name> 0.123 uSv/h          –∏–ª–∏ ¬´‚Ä¶ ¬µR/h¬ª / ¬´‚Ä¶ ¬µSv/h¬ª –≤ <description>
//  ‚Ä¢ —Å—á—ë—Ç        ‚Äî ¬´‚Ä¶ cps¬ª –∏–ª–∏ ¬´CPM Value = ‚Ä¶¬ª
//  ‚Ä¢ –¥–∞—Ç—É        ‚Äî –∫–∞–∫ –≤ parseDate()
// -----------------------------------------------------------------------------
func parseKML(data []byte) ([]database.Marker, error) {
	var markers []database.Marker

	placemarkRe := regexp.MustCompile(`(?s)<Placemark[^>]*>(.*?)</Placemark>`)
	for _, pm := range placemarkRe.FindAllStringSubmatch(string(data), -1) {
		seg := pm[1]

		// --- –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã ---------------------------------------------------
		coordRe := regexp.MustCompile(`<coordinates>\s*([-\d.]+),([-\d.]+)`)
		cm := coordRe.FindStringSubmatch(seg)
		if len(cm) < 3 {
			continue // –±–µ–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç ‚Äî –±–µ—Å–ø–æ–ª–µ–∑–Ω–æ
		}
		lon, lat := parseFloat(cm[1]), parseFloat(cm[2])

		// --- —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è ----------------------------------------------
		name := ""
		if m := regexp.MustCompile(`<name>([^<]+)</name>`).FindStringSubmatch(seg); len(m) > 1 {
			name = strings.TrimSpace(m[1])
		}
		desc := ""
		if m := regexp.MustCompile(`(?s)<description[^>]*>(.*?)</description>`).FindStringSubmatch(seg); len(m) > 1 {
			desc = strings.TrimSpace(m[1])
		}

		// --- –∏–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è ------------------------------------------
		dose   := extractDoseRate(name)
		if dose == 0 {
			dose = extractDoseRate(desc)
		}
		count  := extractCountRate(desc)
		date   := parseDate(desc, getTimeZoneByLongitude(lon))

		markers = append(markers, database.Marker{
			DoseRate:  dose,
			CountRate: count,
			Lat:       lat,
			Lon:       lon,
			Date:      date,
		})
	}
	return markers, nil
}



func processAndStoreMarkers(markers []database.Marker, trackID string, db *database.Database, dbType string) error {
	// –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º TrackID –≤—Å–µ–º –º–∞—Ä–∫–µ—Ä–∞–º
	for i := range markers {
		markers[i].TrackID = trackID
	}

	// –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
	markers = filterZeroMarkers(markers)

	// processAndStoreMarkers()  ‚Äì —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ filterZeroMarkers()
	markers = filterInvalidDateMarkers(markers)  // NEW
	if len(markers) == 0 {
		return fmt.Errorf("all markers have invalid dates")
	}

	// –†–∞—Å—á—ë—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏
	markers = calculateSpeedForMarkers(markers)

	// –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞—Å—á—ë—Ç –¥–ª—è –∑—É–º–æ–≤
	allZoomMarkers := precomputeMarkersForAllZoomLevels(markers)

	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞—Ä–∫–µ—Ä—ã –≤ –ë–î
	for _, m := range allZoomMarkers {
		if err := db.SaveMarkerAtomic(m, dbType); err != nil {
			return fmt.Errorf("error saving marker: %v", err)
		}
	}
	return nil
}

// parseTextRCTRK - –ø–∞—Ä—Å–∏–Ω–≥ .rctrk —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ
func parseTextRCTRK(data []byte) ([]database.Marker, error) {
	var markers []database.Marker
	lines := strings.Split(string(data), "\n")
	for i, line := range lines {
		if i == 0 || strings.HasPrefix(line, "Timestamp") || strings.TrimSpace(line) == "" {
			continue
		}
		fields := strings.Fields(line)
		if len(fields) < 8 {
			log.Printf("Skipping line %d: insufficient fields. Line: %s\n", i+1, line)
			continue
		}
		timeStampStr := fields[1] + " " + fields[2]
		layout := "2006-01-02 15:04:05"
		parsedTime, err := time.Parse(layout, timeStampStr)
		if err != nil {
			log.Printf("Skipping line %d: error parsing time. %v\n", i+1, err)
			continue
		}
		lat := parseFloat(fields[3])
		lon := parseFloat(fields[4])
		if lat == 0 || lon == 0 {
			log.Printf("Skipping line %d: invalid coordinates.\n", i+1)
			continue
		}
		doseRate := parseFloat(fields[6])
		countRate := parseFloat(fields[7])
		if doseRate < 0 || countRate < 0 {
			log.Printf("Skipping line %d: negative dose or count.\n", i+1)
			continue
		}
		marker := database.Marker{
			DoseRate:  doseRate / 100.0,
			CountRate: countRate,
			Lat:       lat,
			Lon:       lon,
			Date:      parsedTime.Unix(),
		}
		markers = append(markers, marker)
	}
	return markers, nil
}

func processKMLFile(file multipart.File, trackID string, db *database.Database, dbType string) error {
	data, err := ioutil.ReadAll(file)
	if err != nil {
		return fmt.Errorf("error reading KML file: %v", err)
	}
	markers, err := parseKML(data)
	if err != nil {
		return fmt.Errorf("error parsing KML file: %v", err)
	}

	return processAndStoreMarkers(markers, trackID, db, dbType)
}

func processKMZFile(file multipart.File, trackID string, db *database.Database, dbType string) error {
	data, err := ioutil.ReadAll(file)
	if err != nil {
		return fmt.Errorf("error reading KMZ file: %v", err)
	}
	zipReader, err := zip.NewReader(bytes.NewReader(data), int64(len(data)))
	if err != nil {
		return fmt.Errorf("error opening KMZ file as ZIP: %v", err)
	}

	for _, zipFile := range zipReader.File {
		if filepath.Ext(zipFile.Name) == ".kml" {
			kmlFile, err := zipFile.Open()
			if err != nil {
				return fmt.Errorf("error opening KML inside KMZ: %v", err)
			}
			defer kmlFile.Close()

			kmlData, err := io.ReadAll(kmlFile)
			if err != nil {
				return fmt.Errorf("error reading KML inside KMZ: %v", err)
			}
			markers, err := parseKML(kmlData)
			if err != nil {
				return fmt.Errorf("error parsing KML inside KMZ: %v", err)
			}

			if err := processAndStoreMarkers(markers, trackID, db, dbType); err != nil {
				return err
			}
		}
	}
	return nil
}

func processRCTRKFile(file multipart.File, trackID string, db *database.Database, dbType string) error {
	data, err := ioutil.ReadAll(file)
	if err != nil {
		return fmt.Errorf("error reading RCTRK file: %v", err)
	}
	rctrkData := database.Data{IsSievert: true}

	if err := json.Unmarshal(data, &rctrkData); err == nil {
		markers := rctrkData.Markers
		if !rctrkData.IsSievert {
			markers = convertRhToSv(markers)
		}
		return processAndStoreMarkers(markers, trackID, db, dbType)
	}

	markers, err := parseTextRCTRK(data)
	if err != nil {
		return fmt.Errorf("error parsing text RCTRK file: %v", err)
	}

	return processAndStoreMarkers(markers, trackID, db, dbType)
}

func processAtomFastFile(file multipart.File, trackID string, db *database.Database, dbType string) error {
	data, err := ioutil.ReadAll(file)
	if err != nil {
		return fmt.Errorf("error reading AtomFast JSON file: %v", err)
	}
	var atomFastData []struct {
		D   float64 `json:"d"`
		Lat float64 `json:"lat"`
		Lng float64 `json:"lng"`
		T   int64   `json:"t"`
	}
	if err := json.Unmarshal(data, &atomFastData); err != nil {
		return fmt.Errorf("error parsing AtomFast file: %v", err)
	}
	var markers []database.Marker
	for _, record := range atomFastData {
		markers = append(markers, database.Marker{
			DoseRate:  record.D,
			Date:      record.T / 1000,
			Lon:       record.Lng,
			Lat:       record.Lat,
			CountRate: record.D,
		})
	}

	return processAndStoreMarkers(markers, trackID, db, dbType)
}

// =====================
// –û–±—Ä–∞–±–æ—Ç–∫–∞ /upload
// =====================
func uploadHandler(w http.ResponseWriter, r *http.Request) {
	if err := r.ParseMultipartForm(100 << 20); err != nil {
		http.Error(w, "Error uploading file", http.StatusInternalServerError)
		return
	}
	files := r.MultipartForm.File["files[]"]
	if len(files) == 0 {
		http.Error(w, "No files selected", http.StatusBadRequest)
		return
	}
	trackID := GenerateSerialNumber()

	var minLat, minLon, maxLat, maxLon float64
	minLat, minLon = 90.0, 180.0
	maxLat, maxLon = -90.0, -180.0

	for _, fileHeader := range files {
		file, err := fileHeader.Open()
		if err != nil {
			http.Error(w, "Error opening file", http.StatusBadRequest)
			return
		}
		defer file.Close()

		ext := strings.ToLower(filepath.Ext(fileHeader.Filename))
		switch ext {
		case ".kml":
			err = processKMLFile(file, trackID, db, *dbType)
		case ".kmz":
			err = processKMZFile(file, trackID, db, *dbType)
		case ".rctrk":
			err = processRCTRKFile(file, trackID, db, *dbType)
		case ".json":
			err = processAtomFastFile(file, trackID, db, *dbType)
		default:
			http.Error(w, "Unsupported file type", http.StatusBadRequest)
			return
		}

		if err != nil {
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}

		// –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞, –∑–∞–ø—Ä–æ—Å–∏–º –º–∞—Ä–∫–µ—Ä—ã –∏–∑ –ë–î, —á—Ç–æ–±—ã –≤—ã—á–∏—Å–ª–∏—Ç—å –≥—Ä–∞–Ω–∏—Ü—ã —Ç—Ä–µ–∫–∞
		markers, err := db.GetMarkersByTrackID(trackID, *dbType)
		if err != nil {
			http.Error(w, "Error fetching markers after upload", http.StatusInternalServerError)
			return
		}

		// –û–±–Ω–æ–≤–∏–º –≥—Ä–∞–Ω–∏—Ü—ã
		for _, marker := range markers {
			if marker.Lat < minLat {
				minLat = marker.Lat
			}
			if marker.Lat > maxLat {
				maxLat = marker.Lat
			}
			if marker.Lon < minLon {
				minLon = marker.Lon
			}
			if marker.Lon > maxLon {
				maxLon = marker.Lon
			}
		}
	}

	if minLat == 90.0 || minLon == 180.0 || maxLat == -90.0 || maxLon == -180.0 {
		log.Println("Error: Unable to calculate bounds, no valid markers found.")
		http.Error(w, "No valid data in file", http.StatusBadRequest)
		return
	}

	log.Printf("Track: %s bounds: minLat=%f, minLon=%f, maxLat=%f, maxLon=%f\n", trackID, minLat, minLon, maxLat, maxLon)
	trackURL := fmt.Sprintf("/trackid/%s?minLat=%f&minLon=%f&maxLat=%f&maxLon=%f&zoom=14&layer=%s",
		trackID, minLat, minLon, maxLat, maxLon, "OpenStreetMap")

	response := map[string]interface{}{
		"status":   "success",
		"trackURL": trackURL,
	}
	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(response)
}

// =====================
// WEB
// =====================
// =====================
// WEB  ‚Äî –≥–ª–∞–≤–Ω–∞—è –∫–∞—Ä—Ç–∞
// =====================
func mapHandler(w http.ResponseWriter, r *http.Request) {
	lang := getPreferredLanguage(r)

	// –ì–æ—Ç–æ–≤–∏–º —à–∞–±–ª–æ–Ω
	tmpl := template.Must(template.New("map.html").Funcs(template.FuncMap{
		"translate": func(key string) string {
			if val, ok := translations[lang][key]; ok {
				return val
			}
			return translations["en"][key]
		},
		"toJSON": func(data interface{}) (string, error) {
			bytes, err := json.Marshal(data)
			return string(bytes), err
		},
	}).ParseFS(content, "public_html/map.html"))

	if CompileVersion == "dev" {
		CompileVersion = "latest"
	}

	// –î–∞–Ω–Ω—ã–µ –¥–ª—è —à–∞–±–ª–æ–Ω–∞
	data := struct {
		Markers      []database.Marker
		Version      string
		Translations map[string]map[string]string
		Lang         string
		DefaultLat   float64
		DefaultLon   float64
		DefaultZoom  int
		DefaultLayer string
	}{
		Markers:      doseData.Markers,
		Version:      CompileVersion,
		Translations: translations,
		Lang:         lang,
		DefaultLat:   *defaultLat,
		DefaultLon:   *defaultLon,
		DefaultZoom:  *defaultZoom,
		DefaultLayer: *defaultLayer,
	}

	// –†–µ–Ω–¥–µ—Ä–∏–º –≤ –±—É—Ñ–µ—Ä, —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å WriteHeader
	var buf bytes.Buffer
	if err := tmpl.Execute(&buf, data); err != nil {
		log.Printf("Error executing template: %v", err)
		http.Error(w, "Internal Server Error", http.StatusInternalServerError)
		return
	}

	w.Header().Set("Content-Type", "text/html; charset=utf-8")
	if _, err := buf.WriteTo(w); err != nil {
		log.Printf("Error writing response: %v", err)
	}
}

// =====================
// WEB  ‚Äî —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Ç—Ä–µ–∫–∞
// =====================
func trackHandler(w http.ResponseWriter, r *http.Request) {
	lang := getPreferredLanguage(r)

	// /trackid/<ID>
	pathParts := strings.Split(r.URL.Path, "/")
	if len(pathParts) < 3 {
		http.Error(w, "TrackID not provided", http.StatusBadRequest)
		return
	}
	trackID := pathParts[2]

	// –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞ (–º–æ–≥—É—Ç –±—ã—Ç—å –Ω—É–ª—è–º–∏)
	minLat, _ := strconv.ParseFloat(r.URL.Query().Get("minLat"), 64)
	minLon, _ := strconv.ParseFloat(r.URL.Query().Get("minLon"), 64)
	maxLat, _ := strconv.ParseFloat(r.URL.Query().Get("maxLat"), 64)
	maxLon, _ := strconv.ParseFloat(r.URL.Query().Get("maxLon"), 64)

	// –ú–∞—Ä–∫–µ—Ä—ã —Ç—Ä–µ–∫–∞ –≤ –∑–∞–¥–∞–Ω–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü–∞—Ö (–º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å—Å—è –ø—É—Å—Ç–æ–π —Å—Ä–µ–∑ ‚Äî —ç—Ç–æ –æ–∫)
	markers, err := db.GetMarkersByTrackIDAndBounds(trackID, minLat, minLon, maxLat, maxLon, *dbType)
	if err != nil {
		http.Error(w, "Error fetching markers", http.StatusInternalServerError)
		return
	}

	// –®–∞–±–ª–æ–Ω —Ç–æ—Ç –∂–µ, —á—Ç–æ –∏ –¥–ª—è –≥–ª–∞–≤–Ω–æ–π –∫–∞—Ä—Ç—ã
	tmpl := template.Must(template.New("map.html").Funcs(template.FuncMap{
		"translate": func(key string) string {
			if val, ok := translations[lang][key]; ok {
				return val
			}
			return translations["en"][key]
		},
		"toJSON": func(data interface{}) (string, error) {
			bytes, err := json.Marshal(data)
			return string(bytes), err
		},
	}).ParseFS(content, "public_html/map.html"))

	data := struct {
		Markers      []database.Marker
		Version      string
		Translations map[string]map[string]string
		Lang         string
		DefaultLat   float64
		DefaultLon   float64
		DefaultZoom  int
		DefaultLayer string
	}{
		Markers:      markers,
		Version:      CompileVersion,
		Translations: translations,
		Lang:         lang,
		DefaultLat:   *defaultLat,
		DefaultLon:   *defaultLon,
		DefaultZoom:  *defaultZoom,
		DefaultLayer: *defaultLayer,
	}

	var buf bytes.Buffer
	if err := tmpl.Execute(&buf, data); err != nil {
		log.Printf("Error executing template: %v", err)
		http.Error(w, "Internal Server Error", http.StatusInternalServerError)
		return
	}

	w.Header().Set("Content-Type", "text/html; charset=utf-8")
	if _, err := buf.WriteTo(w); err != nil {
		log.Printf("Error writing response: %v", err)
	}
}

// getMarkersHandler ‚Äî –±–µ—Ä—ë—Ç –º–∞—Ä–∫–µ—Ä—ã –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –æ–∫–Ω–µ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ö
// +–ù–û–í–û–ï: dateFrom/dateTo (UNIX-seconds) –¥–∏–∞–ø–∞–∑–æ–Ω –≤—Ä–µ–º–µ–Ω–∏.
func getMarkersHandler(w http.ResponseWriter, r *http.Request) {
	q              := r.URL.Query()
	zoom, _        := strconv.Atoi(q.Get("zoom"))
	minLat, _      := strconv.ParseFloat(q.Get("minLat"), 64)
	minLon, _      := strconv.ParseFloat(q.Get("minLon"), 64)
	maxLat, _      := strconv.ParseFloat(q.Get("maxLat"), 64)
	maxLon, _      := strconv.ParseFloat(q.Get("maxLon"), 64)
	trackID        := q.Get("trackID")

	// ----- ‚úàÔ∏èüöóüö∂ —Ñ–∏–ª—å—Ç—Ä —Å–∫–æ—Ä–æ—Å—Ç–∏  ---------------------------------
	var sr []database.SpeedRange
	if s := q.Get("speeds"); s != "" {
		for _, tag := range strings.Split(s, ",") {
			if r, ok := speedCatalog[tag]; ok {
				sr = append(sr, database.SpeedRange(r))
			}
		}
	}
	if len(sr) == 0 && q.Get("speeds") != "" { // –≤—Å–µ –≤—ã–∫–ª—é—á–µ–Ω—ã
		w.Header().Set("Content-Type", "application/json")
		_, _ = w.Write([]byte("[]"))
		return
	}

	// ----- ‚è±Ô∏è  —Ñ–∏–ª—å—Ç—Ä –≤—Ä–µ–º–µ–Ω–∏  ------------------------------------
	var (
		dateFrom int64
		dateTo   int64
	)
	if s := q.Get("dateFrom"); s != "" {
		dateFrom, _ = strconv.ParseInt(s, 10, 64)
	}
	if s := q.Get("dateTo"); s != "" {
		dateTo, _ = strconv.ParseInt(s, 10, 64)
	}

	// ----- –∑–∞–ø—Ä–æ—Å –∫ –ë–î  ------------------------------------------
	var (
		markers []database.Marker
		err     error
	)
	if trackID != "" {
		markers, err = db.GetMarkersByTrackIDZoomBoundsSpeed(
			trackID, zoom, minLat, minLon, maxLat, maxLon,
			dateFrom, dateTo, sr, *dbType)
	} else {
		markers, err = db.GetMarkersByZoomBoundsSpeed(
			zoom, minLat, minLon, maxLat, maxLon,
			dateFrom, dateTo, sr, *dbType)
	}
	if err != nil {
		http.Error(w, "Error fetching markers", http.StatusInternalServerError)
		return
	}

	w.Header().Set("Content-Type", "application/json")
	_ = json.NewEncoder(w).Encode(markers)
}

// =====================
// MAIN
// =====================

// main parses flags, initialises the DB & routes, then either
// (a) serves plain HTTP on a custom port, or
// (b) if -domain is given, serves ACME-backed HTTPS on 443 plus
//     an ACME/redirect helper on 80.
//
// If any web-server returns an error it is only logged ‚Äì the
// application continues running.  A final `select{}` keeps the
// main goroutine alive without resorting to mutexes.




// main: –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–ª–∞–≥–æ–≤, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î –∏ –∑–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–æ–≤.
// –î–æ–±–∞–≤–ª–µ–Ω withServerHeader –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.
// =====================
// MAIN
// =====================
func main() {
	// 1. –§–ª–∞–≥–∏ –∏ –≤–µ—Ä—Å–∏–∏
	flag.Parse()
	loadTranslations(content, "public_html/translations.json")

	if *version {
		fmt.Printf("chicha-isotope-map version %s\n", CompileVersion)
		return
	}

	// 2. –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –ø—Ä–∏–≤–∏–ª–µ–≥–∏—è—Ö (–¥–ª—è :80 / :443)
	if *domain != "" && runtime.GOOS != "windows" && os.Geteuid() != 0 {
		log.Println("‚ö†  Binding to :80 / :443 requires super-user rights; run with sudo or as root.")
	}

	// 3. –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
	dbCfg := database.Config{
		DBType:    *dbType,
		DBPath:    *dbPath,
		DBHost:    *dbHost,
		DBPort:    *dbPort,
		DBUser:    *dbUser,
		DBPass:    *dbPass,
		DBName:    *dbName,
		PGSSLMode: *pgSSLMode,
		Port:      *port,
	}
	var err error
	db, err = database.NewDatabase(dbCfg)
	if err != nil { log.Fatalf("DB init: %v", err) }
	if err = db.InitSchema(dbCfg); err != nil { log.Fatalf("DB schema: %v", err) }

	// 4. –ú–∞—Ä—à—Ä—É—Ç—ã –∏ —Å—Ç–∞—Ç–∏–∫–∞
	staticFS, err := fs.Sub(content, "public_html")
	if err != nil { log.Fatalf("static fs: %v", err) }

	http.Handle("/static/", http.StripPrefix("/static/",
		http.FileServer(http.FS(staticFS))))
	http.HandleFunc("/",            mapHandler)
	http.HandleFunc("/upload",      uploadHandler)
	http.HandleFunc("/get_markers", getMarkersHandler)
	http.HandleFunc("/trackid/",    trackHandler)

	rootHandler := withServerHeader(http.DefaultServeMux)

	// 5. HTTP/HTTPS-—Å–µ—Ä–≤–µ—Ä—ã
	if *domain != "" {
		// –î–≤–æ–π–Ω–æ–π —Å–µ—Ä–≤–µ—Ä :80 + :443 —Å Let‚Äôs Encrypt
		go serveWithDomain(*domain, rootHandler)
	} else {
		// –û–±—ã—á–Ω—ã–π HTTP –Ω–∞ –ø–æ—Ä—Ç –∏–∑ -port
		addr := fmt.Sprintf(":%d", *port)
		go func() {
			log.Printf("HTTP server ‚ûú http://localhost:%s", addr)
			if err := http.ListenAndServe(addr, rootHandler); err != nil {
				log.Printf("HTTP server error: %v", err)
			}
		}()
	}

	// 6. –î–µ—Ä–∂–∏–º main-goroutine –∂–∏–≤–æ–π
	select {}
}

