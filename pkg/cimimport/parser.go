package cimimport

import (
	"bufio"
	"encoding/json"
	"fmt"
	"io"
	"strings"
	"time"

	"chicha-isotope-map/pkg/database"
	"chicha-isotope-map/pkg/trackjson"
)

// ==========================
// .cim JSON track utilities
// ==========================

// File represents the JSON structure produced by the archive exporter.
// Keeping the shape explicit allows the importer to validate the payload
// without relying on reflection-heavy generic maps, which keeps decoding
// cheap and predictable for streaming uploads.
type File struct {
	TrackID     string            `json:"trackID"`
	TrackIndex  int64             `json:"trackIndex"`
	APIURL      string            `json:"apiURL"`
	FirstID     int64             `json:"firstID"`
	LastID      int64             `json:"lastID"`
	MarkerCount int64             `json:"markerCount"`
	Markers     []markerPayload   `json:"markers"`
	Disclaimers map[string]string `json:"disclaimers"`
}

// markerPayload mirrors the JSON structure generated by trackjson.MakeMarkerPayload.
// We keep the struct local so future changes in the archive schema remain isolated
// here without forcing the rest of the codebase to update immediately.
type markerPayload struct {
	ID                 int64    `json:"id"`
	TimeUnix           int64    `json:"timeUnix"`
	TimeUTC            string   `json:"timeUTC"`
	Lat                float64  `json:"lat"`
	Lon                float64  `json:"lon"`
	AltitudeM          *float64 `json:"altitudeM"`
	DoseMicroSvH       float64  `json:"doseRateMicroSvH"`
	DoseMicroRoentgenH float64  `json:"doseRateMicroRh"`
	CountRateCPS       float64  `json:"countRateCPS"`
	SpeedMS            float64  `json:"speedMS"`
	SpeedKMH           float64  `json:"speedKMH"`
	TemperatureC       *float64 `json:"temperatureC"`
	HumidityPercent    *float64 `json:"humidityPercent"`
	DetectorName       string   `json:"detectorName"`
	DetectorType       string   `json:"detectorType"`
	RadiationTypes     []string `json:"radiationTypes"`
}

// Parse consumes the provided reader and decodes a JSON .cim payload.
// A small buffered reader keeps the decoder from issuing tiny syscalls
// when uploads arrive over the network, aligning with the "Performance is
// often gained by eliminating unnecessary work" proverb.
func Parse(r io.Reader) (File, error) {
	dec := json.NewDecoder(bufio.NewReader(r))
	var doc File
	if err := dec.Decode(&doc); err != nil {
		return File{}, fmt.Errorf("decode .cim: %w", err)
	}
	if len(doc.Markers) == 0 {
		return File{}, fmt.Errorf("decode .cim: no markers present")
	}
	return doc, nil
}

// ToDatabaseMarkers converts the parsed payload into database markers while
// computing the geographic bounds. A goroutine streams converted markers
// through a channel so large tracks remain memory-friendly and follow the
// project rule of communicating over channels instead of locks.
func (f File) ToDatabaseMarkers(defaultTrackID string) ([]database.Marker, database.Bounds) {
	bounds := database.Bounds{MinLat: 90, MinLon: 180, MaxLat: -90, MaxLon: -180}
	markers := make([]database.Marker, 0, len(f.Markers))
	updates := make(chan database.Marker)

	go func(trackID string) {
		defer close(updates)
		for _, raw := range f.Markers {
			marker := convertMarker(raw)
			marker.TrackID = trackID
			updates <- marker
		}
	}(strings.TrimSpace(defaultTrackID))

	for marker := range updates {
		if marker.Lat < bounds.MinLat {
			bounds.MinLat = marker.Lat
		}
		if marker.Lat > bounds.MaxLat {
			bounds.MaxLat = marker.Lat
		}
		if marker.Lon < bounds.MinLon {
			bounds.MinLon = marker.Lon
		}
		if marker.Lon > bounds.MaxLon {
			bounds.MaxLon = marker.Lon
		}
		markers = append(markers, marker)
	}

	if len(markers) == 0 {
		bounds = database.Bounds{}
	}
	return markers, bounds
}

// convertMarker keeps the unit conversions close to the parser so the rest of the
// import pipeline can operate on familiar database markers without worrying about
// the nuances of historical payloads.
func convertMarker(raw markerPayload) database.Marker {
	dose := raw.DoseMicroSvH
	if dose == 0 && raw.DoseMicroRoentgenH != 0 {
		dose = raw.DoseMicroRoentgenH / trackjson.MicroRoentgenPerMicroSievert
	}

	speed := raw.SpeedMS
	if speed == 0 && raw.SpeedKMH != 0 {
		speed = raw.SpeedKMH / 3.6
	}

	var altitude float64
	var altitudeValid bool
	if raw.AltitudeM != nil {
		altitude = *raw.AltitudeM
		altitudeValid = true
	}

	var temperature float64
	var temperatureValid bool
	if raw.TemperatureC != nil {
		temperature = *raw.TemperatureC
		temperatureValid = true
	}

	var humidity float64
	var humidityValid bool
	if raw.HumidityPercent != nil {
		humidity = *raw.HumidityPercent
		humidityValid = true
	}

	detectorType := strings.TrimSpace(raw.DetectorType)
	if detectorType == "" {
		detectorType = detectorTypeFromName(raw.DetectorName)
	}

	radiation := strings.Join(normaliseRadiation(raw.RadiationTypes), ",")

	return database.Marker{
		DoseRate:         dose,
		Date:             normaliseUnix(raw.TimeUnix, raw.TimeUTC),
		Lon:              raw.Lon,
		Lat:              raw.Lat,
		CountRate:        raw.CountRateCPS,
		Speed:            speed,
		Altitude:         altitude,
		Temperature:      temperature,
		Humidity:         humidity,
		Detector:         detectorType,
		Radiation:        radiation,
		AltitudeValid:    altitudeValid,
		TemperatureValid: temperatureValid,
		HumidityValid:    humidityValid,
		Zoom:             0,
	}
}

// normaliseUnix translates mixed timestamp representations into plain seconds.
// The exporter already follows this convention; the helper ensures future tweaks
// do not leak milliseconds into the storage layer.
func normaliseUnix(value int64, iso string) int64 {
	switch {
	case value > 1_000_000_000_000:
		return value / 1000
	case value > 0:
		return value
	}
	if ts, err := time.Parse(time.RFC3339Nano, strings.TrimSpace(iso)); err == nil {
		return ts.Unix()
	}
	return 0
}

// normaliseRadiation deduplicates radiation channel hints so insert queries stay small.
func normaliseRadiation(values []string) []string {
	if len(values) == 0 {
		return nil
	}
	seen := make(map[string]struct{}, len(values))
	out := make([]string, 0, len(values))
	for _, raw := range values {
		trimmed := strings.ToLower(strings.TrimSpace(raw))
		if trimmed == "" {
			continue
		}
		if _, ok := seen[trimmed]; ok {
			continue
		}
		seen[trimmed] = struct{}{}
		out = append(out, trimmed)
	}
	if len(out) == 0 {
		return nil
	}
	return out
}

// detectorTypeFromName extracts the detector type encoded in stable names.
func detectorTypeFromName(name string) string {
	trimmed := strings.TrimSpace(name)
	if trimmed == "" {
		return ""
	}
	if idx := strings.Index(trimmed, ":"); idx >= 0 && idx+1 < len(trimmed) {
		candidate := strings.TrimSpace(trimmed[idx+1:])
		if candidate != "" {
			return candidate
		}
	}
	return ""
}
